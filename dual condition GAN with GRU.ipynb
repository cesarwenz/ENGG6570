{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74bb8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from numpy.random import randn\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7452b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 11GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b603f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec8104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape, vector_shape, n_classes=7):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_src_image = Input(shape=image_shape)\n",
    "    # vector input\n",
    "    in_target = Input(shape=(vector_shape[0], vector_shape[1]))\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # Vector layer\n",
    "    n_nodes = (image_shape[0] * image_shape[1] * image_shape[2])\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # scale up to image dimensions with linear\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((image_shape[0], image_shape[1], image_shape[2]))(li)\n",
    "    # GRU or LSTM Model\n",
    "    p = LSTM(200, activation='relu')(in_target)\n",
    "    #p = GRU(200, activation='relu')(in_target)\n",
    "    p = Dense(n_nodes)(p)\n",
    "    # Reshape and mergo to image dimension\n",
    "    p = Reshape((image_shape[0], image_shape[1], image_shape[2]))(p)\n",
    "    merged = Concatenate()([p, in_src_image, li])\n",
    "    # concatenate images channel-wise\n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Flatten()(d)\n",
    "    d = Dropout(0.4)(d)\n",
    "    out_layer = Dense(1, activation='sigmoid')(d)\n",
    "    # define model\n",
    "    model = Model([in_src_image, in_target, in_label], out_layer)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ff581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # add downsampling layer\n",
    "    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same',\n",
    "    kernel_initializer=init)(layer_in)\n",
    "    # conditionally add batch normalization\n",
    "    if batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    # leaky relu activation\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ee8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(in_shape, vector_shape, latent_dim, n_classes=7):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "    in_lat = Input(shape=latent_dim)\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    li = Dense(latent_dim)(li)\n",
    "    li = Reshape([latent_dim])(li)\n",
    "    gen = LeakyReLU(alpha=0.2)(in_lat)\n",
    "    # merge image gen and label input\n",
    "    # encoder model\n",
    "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    e3 = define_encoder_block(e2, 256)\n",
    "    e4 = define_encoder_block(e3, 512)\n",
    "    e5 = define_encoder_block(e4, 512)\n",
    "    e6 = define_encoder_block(e5, 512)\n",
    "    e7 = define_encoder_block(e6, 512)\n",
    "    # bottleneck, no batch norm and relu\n",
    "    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "    b = Activation('relu')(b)\n",
    "    b = Flatten()(b)\n",
    "    # Merge latent space variable input with network\n",
    "    b = Concatenate()([b, gen, li])\n",
    "    # Reshape to vector size\n",
    "    n_nodes = (vector_shape[0] * vector_shape[1])\n",
    "    b = Dense(n_nodes)(b)\n",
    "    b = Reshape([vector_shape[0], vector_shape[1]])(b)\n",
    "    # encoder-decoder LSTM model\n",
    "    d = GRU(200, activation='relu')(b)\n",
    "    d = RepeatVector(vector_shape[0])(d)\n",
    "    d = GRU(200, activation='relu', return_sequences=True)(d)\n",
    "    # output\n",
    "    out_layer = Dense(3)(d)\n",
    "\n",
    "    # define model input & output\n",
    "    model = Model([in_image, in_lat, in_label], out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bc38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd58e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape, vector_shape, latent_dim):\n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    # define the source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    in_lat = Input(shape=latent_dim)\n",
    "    in_label = Input(shape=(1,))\n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model([in_src, in_lat, in_label])\n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out, in_label])\n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model([in_src, in_lat, in_label], [dis_out, gen_out])\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0005, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e283c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "\t# load compressed arrays\n",
    "\tdata = load(filename)\n",
    "\t# unpack arrays\n",
    "\tX1, X2, X3 = data['arr_0'], data['arr_1'], data['arr_2']\n",
    "\treturn [X1, X2, X3-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c1479f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# unpack dataset\n",
    "\timg, vec, label = dataset\n",
    "\t# choose random instances\n",
    "\tix = randint(0, img.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX1, X2, X3 = img[ix], vec[ix], label[ix]\n",
    "\t# generate 'real' class labels \n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn [X1, X2, X3], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52bccb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ac0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, label, n_samples):\n",
    "    # Generate latent space points\n",
    "    z_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # generate fake instance\n",
    "    X = g_model.predict([samples, z_input, label])\n",
    "    # create 'fake' class labels \n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfebda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay trajectories (data_y) to the image (data_x)\n",
    "def create_trajectory(data_x, data_y, obs_len=10):\n",
    "    # Calibration parameter to overlay for a 1280x360 resolution image\n",
    "    K = np.array([[537.023764, 0, 640 , 0], \n",
    "                    [0 , 537.023764, 180, 0], \n",
    "                    [0, 0, 1, 0]])\n",
    "    # Rotation matrix to obtain egocentric trajectory\n",
    "    Rt = np.array([[0.028841, 0.007189, 0.999558, 1.481009],\n",
    "                    [-0.999575,  0.004514,  0.028809,  0.296583],\n",
    "                    [ 0.004305,  0.999964, -0.007316, -1.544537],\n",
    "                    [ 0.      ,  0.      ,  0.      ,  1.      ]])\n",
    "\n",
    "    # Resize data back to 1280x360\n",
    "    data_x = cv2.resize(data_x, (1280,360))\n",
    "    # Add column of ones for rotation matrix multiplication\n",
    "    data_y = np.hstack((data_y, np.ones((len(data_y),1))))\n",
    "    # Draw points\n",
    "    for m in range(obs_len, data_y.shape[0]):\n",
    "        # Rotation matrix multiplication of trajectory \n",
    "        A = np.matmul(np.linalg.inv(Rt), data_y[m, :].reshape(4, 1))\n",
    "        # Egocentric view of trajectory\n",
    "        B = np.matmul(K, A)\n",
    "        # Circle location of trajectories \n",
    "        x = int(B[0, 0] * 1.0 / B[2, 0])\n",
    "        y = int(B[1, 0] * 1.0 / B[2, 0])\n",
    "        if (x < 0 or x > 1280 - 1 or y > 360 - 1):\n",
    "            continue\n",
    "        # Use opencv to overlay trajectories\n",
    "        data_x = cv2.circle(data_x, (x, y), 3, (0, 0, 255), -1)\n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8f6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_drvact_text(drvact):\n",
    "    text = '[warnings] drvact label is not defined ...'\n",
    "    if (drvact == 1):\n",
    "        text = 'Go'\n",
    "    elif (drvact == 2):\n",
    "        text = 'Turn Left'\n",
    "    elif (drvact == 3):\n",
    "        text = 'Turn Right'\n",
    "    elif (drvact == 4):\n",
    "        text = 'U-turn'\n",
    "    elif (drvact == 5):\n",
    "        text = 'Left LC'\n",
    "    elif (drvact == 6):\n",
    "        text = 'Right LC'\n",
    "    elif (drvact == 7):\n",
    "        text = 'Avoidance'\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c71f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, dataset, n_samples=1):\n",
    "    # select a sample of input images\n",
    "    [X_real_img, X_real_vec, X_label], _ = generate_real_samples(dataset, n_samples)\n",
    "    # generate a batch of fake samples\n",
    "    X_fake_vec, _ = generate_fake_samples(g_model, X_real_img, X_label, n_samples)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_real_img = (X_real_img + 1) / 2.0\n",
    "    pyplot.figure(figsize=(32.0, 20.0))\n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        orig_image = (X_real_img[i]* 255).astype(np.uint8)\n",
    "        orig_image = cv2.resize(orig_image, (1280,360))\n",
    "        pyplot.subplot(3, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(orig_image)\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        fake_sample = create_trajectory((X_real_img[i]* 255).astype(np.uint8), X_fake_vec[i])\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(fake_sample)\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        true_sample = create_trajectory((X_real_img[i]* 255).astype(np.uint8), X_real_vec[i])\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(true_sample)\n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%06d.png' % (step+1)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    filename2 = 'model_%06d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e1f30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "def train(d_model, g_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=3):\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(dataset[0]) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # select a batch of real samples\n",
    "        [X_real_img, X_real_vec, X_label], y_real = generate_real_samples(dataset, n_batch)\n",
    "        # generate a batch of fake samples\n",
    "        X_fake_vec, y_fake = generate_fake_samples(g_model, X_real_img, X_label, n_batch)\n",
    "        # update discriminator for real samples\n",
    "        d_loss1 = d_model.train_on_batch([X_real_img, X_real_vec, X_label], y_real)\n",
    "        # update discriminator for generated samples\n",
    "        d_loss2 = d_model.train_on_batch([X_real_img, X_fake_vec, X_label], y_fake)\n",
    "        X_lat = generate_latent_points(latent_dim, n_batch)\n",
    "        # update the generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch([X_real_img, X_lat, X_label], [y_real, X_real_vec])\n",
    "        # summarize performance\n",
    "        print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "        # summarize model performance\n",
    "        if (i+1) % int(bat_per_epo) == 0:\n",
    "            summarize_performance(i, g_model, dataset)\n",
    "            print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12bca134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (16805, 256, 256, 3) (16805, 40, 3) (16805,)\n",
      "CPU times: user 22.8 s, sys: 724 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load image data\n",
    "dataset = load_real_samples('./dual_condition_dataset_train.npz')\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape, dataset[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4025fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "vector_shape = dataset[1].shape[1:]\n",
    "latent_dim = 512\n",
    "# %%\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape, vector_shape)\n",
    "g_model = define_generator(image_shape, vector_shape, latent_dim)\n",
    "# %%\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape, vector_shape, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d0f888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 3136        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  524544      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 512)    4194816     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 512)    4194816     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 4, 4, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 512)    4194816     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 1, 512)    4194816     leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        350         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1, 1, 512)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 512)       26112       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 512)          0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1536)         0           flatten_1[0][0]                  \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          184440      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 40, 3)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 200)          123000      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 40, 200)      0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 40, 200)      241200      repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 40, 3)        603         gru_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 20,121,241\n",
      "Trainable params: 20,116,377\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#see model summary\n",
    "print(g_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4f2217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, d1[0.749] d2[3.211] g[237.643]\n",
      ">2, d1[0.042] d2[0.755] g[330.601]\n",
      ">3, d1[0.068] d2[0.518] g[447.284]\n",
      ">4, d1[0.176] d2[0.871] g[240.621]\n",
      ">5, d1[0.276] d2[0.448] g[281.403]\n",
      ">6, d1[0.006] d2[0.276] g[524.918]\n",
      ">7, d1[0.008] d2[0.082] g[557.915]\n",
      ">8, d1[0.487] d2[0.231] g[283.763]\n",
      ">9, d1[0.016] d2[0.074] g[378.635]\n",
      ">10, d1[0.327] d2[0.678] g[132.655]\n",
      ">11, d1[0.007] d2[0.053] g[422.979]\n",
      ">12, d1[0.001] d2[0.159] g[354.715]\n",
      ">13, d1[0.090] d2[0.431] g[386.488]\n",
      ">14, d1[0.121] d2[0.277] g[361.035]\n",
      ">15, d1[0.470] d2[0.320] g[315.935]\n",
      ">16, d1[0.167] d2[0.260] g[405.128]\n",
      ">17, d1[0.170] d2[0.164] g[426.582]\n",
      ">18, d1[0.196] d2[0.209] g[306.414]\n",
      ">19, d1[0.187] d2[0.094] g[277.914]\n",
      ">20, d1[0.176] d2[0.093] g[309.778]\n",
      ">21, d1[0.339] d2[0.370] g[217.645]\n",
      ">22, d1[0.081] d2[0.075] g[301.127]\n",
      ">23, d1[0.034] d2[0.168] g[360.469]\n",
      ">24, d1[0.043] d2[0.153] g[367.549]\n",
      ">25, d1[1.274] d2[1.794] g[267.912]\n",
      ">26, d1[1.589] d2[0.133] g[258.608]\n",
      ">27, d1[0.716] d2[0.263] g[280.939]\n",
      ">28, d1[0.697] d2[0.266] g[183.994]\n",
      ">29, d1[0.440] d2[0.356] g[209.634]\n",
      ">30, d1[0.392] d2[0.223] g[282.129]\n",
      ">31, d1[0.758] d2[0.159] g[296.679]\n",
      ">32, d1[0.908] d2[0.192] g[134.853]\n",
      ">33, d1[0.373] d2[0.125] g[344.473]\n",
      ">34, d1[0.193] d2[0.160] g[471.824]\n",
      ">35, d1[0.126] d2[0.236] g[457.349]\n",
      ">36, d1[0.240] d2[0.187] g[286.652]\n",
      ">37, d1[0.230] d2[0.351] g[161.285]\n",
      ">38, d1[0.094] d2[0.112] g[443.654]\n",
      ">39, d1[0.608] d2[0.171] g[172.370]\n",
      ">40, d1[0.105] d2[0.159] g[367.602]\n",
      ">41, d1[0.144] d2[0.162] g[277.464]\n",
      ">42, d1[0.283] d2[0.312] g[199.366]\n",
      ">43, d1[0.163] d2[0.157] g[243.982]\n",
      ">44, d1[0.197] d2[0.213] g[322.687]\n",
      ">45, d1[0.166] d2[0.140] g[274.332]\n",
      ">46, d1[0.182] d2[0.148] g[335.880]\n",
      ">47, d1[0.208] d2[0.175] g[197.275]\n",
      ">48, d1[0.161] d2[0.174] g[235.564]\n",
      ">49, d1[0.235] d2[0.094] g[262.487]\n",
      ">50, d1[0.082] d2[0.142] g[353.660]\n",
      ">51, d1[0.175] d2[0.174] g[327.102]\n",
      ">52, d1[0.063] d2[0.249] g[280.406]\n",
      ">53, d1[0.116] d2[0.086] g[271.337]\n",
      ">54, d1[0.089] d2[0.040] g[418.662]\n",
      ">55, d1[0.998] d2[0.258] g[240.637]\n",
      ">56, d1[0.059] d2[0.075] g[344.997]\n",
      ">57, d1[0.629] d2[0.203] g[210.713]\n",
      ">58, d1[0.217] d2[0.410] g[303.166]\n",
      ">59, d1[0.075] d2[0.115] g[397.463]\n",
      ">60, d1[0.214] d2[0.100] g[174.810]\n",
      ">61, d1[0.122] d2[0.125] g[347.580]\n",
      ">62, d1[0.000] d2[0.040] g[446.484]\n",
      ">63, d1[0.088] d2[0.162] g[178.239]\n",
      ">64, d1[0.097] d2[0.051] g[233.654]\n",
      ">65, d1[0.472] d2[1.135] g[239.362]\n",
      ">66, d1[0.279] d2[0.025] g[259.017]\n",
      ">67, d1[0.742] d2[0.064] g[177.292]\n",
      ">68, d1[0.906] d2[0.077] g[157.056]\n",
      ">69, d1[0.157] d2[0.121] g[280.897]\n",
      ">70, d1[0.197] d2[0.119] g[368.469]\n",
      ">71, d1[0.090] d2[0.051] g[312.957]\n",
      ">72, d1[0.486] d2[0.107] g[192.224]\n",
      ">73, d1[0.302] d2[0.037] g[286.599]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0ab14bc271cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-473ecbcd40ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(d_model, g_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mX_fake_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_real_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# update discriminator for real samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_real_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_real_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# update discriminator for generated samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0md_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_real_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fake_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n\u001b[1;32m   1726\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train(d_model, g_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224677a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec964d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd096fc4c12eed3e18ead224912196259d9b4ba259ad818a335a1ec786e41f96ad8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
